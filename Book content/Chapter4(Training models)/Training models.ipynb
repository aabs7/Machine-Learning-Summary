{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model prediction\n",
    "\n",
    "$y = \\theta_0x_0 + \\theta_1x_1 + \\theta_2x_2 + .... + \\theta_nx_n$\n",
    "\n",
    "This can be written much more concisely using a vectorized form as shown below:\n",
    "\n",
    "$y = h_{\\theta}(x) = \\theta.x$\n",
    "\n",
    "- $\\theta$ is the model's parameter vector, containing the bias term $\\theta_0$ and the feature weights $\\theta_1$ to $\\theta_n$\n",
    "\n",
    "add $x_0 = 1$ to each instance to create $x_b$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00499775]\n",
      " [2.8540897 ]]\n"
     ]
    }
   ],
   "source": [
    "X_b = np.c_[np.ones((100,1)),X]\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "print(theta_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expected $\\theta_{0}$ to be 4 and $\\theta_{1}$ to be 3. Close enough, but the gaussian noise made it impossible to recover the exact parameters of the original function.\n",
    "\n",
    "Now predicting the value of y using the theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00499775]\n",
      " [9.71317716]]\n"
     ]
    }
   ],
   "source": [
    "X_new = np.array([[0],[2]])\n",
    "X_new_b = np.c_[np.ones((2,1)),X_new] # add x0 = 1 to each instance\n",
    "y_predict = X_new_b @ theta_best\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEHCAYAAACwUAEWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjLUlEQVR4nO3dfZQcdZ3v8fc3M5k8QICQBIlAmCAIgiCE4aETkjTGh4gg967eBY48yIMRFxRZ1IXLuurN3oWzesTdg+ua6yIiHlYUn64rXnBkJkAmgUkMSXh+NCQGE4IYCMlMkvneP37ddE8zXdMz3VXVPfN5nTNneqqqq35d6dSnfr9f1a/M3RERESlnTNoFEBGR+qagEBGRSAoKERGJpKAQEZFICgoREYnUnHYBKjF16lRvbW1NuxgiIg1l5cqVL7v7tGrX0xBB0draSnd3d9rFEBFpKGb2h1qsR01PIiISSUEhIiKRFBQiIhJJQSEiIpEUFCIiEklBISIikRQUIiISSUEhIiKRFBQiIhJJQSEiIpFiCwozu8XMNpvZugHmXWNmbmZT49q+iIjURpw1iluBhaUTzewQ4APA+hi3LSIiNRJbULj7UuCVAWbdBHwR0MO6RUQaQKJ9FGZ2NrDR3R+pYNlFZtZtZt1btmxJoHQiIjKQxILCzCYC/xP4h0qWd/cl7t7m7m3TplU9nLqIiAxTkjWKdwAzgUfM7AXgYGCVmR2YYBlERGSIEntwkbuvBQ7I/50LizZ3fzmpMoiIyNDFeXnsHUAXcKSZbTCzS+PaloiIxCe2GoW7nzfI/Na4ti0iIrWjO7NFRCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCLFFhRmdouZbTazdUXTvmZmT5jZGjP7mZntF9f2RUSkNuKsUdwKLCyZdi/wbnc/DngKuC7G7YuISA3EFhTuvhR4pWTaPe6+O/fncuDguLYvIiK1kWYfxSXA3eVmmtkiM+s2s+4tW7YkWCwRESmWSlCY2fXAbuCH5ZZx9yXu3ububdOmTUuucCIi0k9z0hs0s08AZwIL3N2T3r6IiAxNokFhZguBLwLz3f2NJLctIiLDE+flsXcAXcCRZrbBzC4FbgYmAfea2Woz+/e4ti8iIrURW43C3c8bYPJ/xLU9ERGJh+7MFhFpUF1dcMMN4XecEu/MFhGR6nV1wYIF0NsLLS3Q3g6ZTDzbUo1CRKQBdXSEkNizJ/zu6IhvWwoKEZEGlM2GmkRTU/idzca3LTU9iYg0oEwmNDd1dISQiKvZCRQUIiINK5OJNyDy1PQkIiKRFBQiIhJJQSEiIpEUFCIiEklBISIikRQUIiIjRFxDeujyWBGREWCgIT1qRTUKEZERIM4hPRQUIiIjQJxDeqjpSURkBIhzSA8FhYjICBHXkB5qehKRUSGph/yMRKpRiMiIl+RDfkYi1ShEZMRL8iE/I1FsQWFmt5jZZjNbVzRtfzO718yezv2eHNf2RUTyknzIz0gUZ43iVmBhybRrgXZ3PwJoz/0tIhKr/BVBixer2Wk4YuujcPelZtZaMvlsIJt7/X2gA/i7uMogIpI33CuCurqSeYpcPUu6M/tt7r4p9/ol4G3lFjSzRcAigBkzZiRQNBGR/tQJHqTWme3uDnjE/CXu3ububdOmTUuwZCKNTZeB1o46wYOkaxR/MrPp7r7JzKYDmxPevsiIpjPg2sp3guf352jtBE86KH4JXATcmPv9i4S3LzKiDXQGnERQjNR2/DiHxRhI1fvRHV54ATo7w0+NxBYUZnYHoeN6qpltAL5MCIg7zexS4A/AX8e1fZHRKI0z4JFei4lrWIxSw9qP7vDss4Vg6OyE9evDvClTala2OK96Oq/MrAVxbVNktEv6DBjSq8VUq95qQRXtR3d46qn+wbBxY5h3wAEwfz588Yvh99FHhxtHakBDeIiMMEmdAec1Yjv+YGfvaYTIgPvRHR5/vH8wvPRSeMOBB4aF5s8PP0cdBWaxlE1BISJVSaMWU62os/e0mtIyGWi/t4+OOzeTbX6AzDd+BEuXwubcNT8HHRQKlg+GI46ILRhKKShEpGpJ12KqFVULSrQpra8P1q4NG+nsJLN0KZmtW8O8GTNg4cJCMBx2WGLBUEpBIVKH6q39PE5pfNaoWlCsTWl79sAjj7wZDNx/P/z5z2HezJlw1lmF5qTW1hpuuDoKCpE6M9KvIiqW5mctVwuqaVPa7t3w+98XguGBB+AvfwnzDj8c/uqvCsFwyCFVbCheCgqROtOoVxENR0cH9PSEFpienvg+61BrLYM1pZVd365dsHJlCIWODnjwQXjttTDvyCPhnHPCm+bNC30ODUJBIVJnGvEqosGUO7BOmRJCAsLvGl7632/btay19F+f037TWjJbfxU+4LJlsH17WPDoo+H88wt9DAceWJPPkwYFhUidqferiIZ6dh51oN66FcaMCSExZkz4u9ZqWkPbuZOO722id+eh7PEx9O7YTcfld5DhRjj2WLj44hAK8+aF+xqGqKsLbrstvL7wwvr5t1dQiNSher2KaDhn51EH6mwWxo2Lp/aUD7QpU6qooe3YAcuXF5qSli8n23MCLbTTSwstzU528UK47BqYOrXq8p5+emiCA7jllvppdlRQiEjFhnN2XtqUNmVKGN02XyOJo/ZUGmjf/GaorQy6je3bw5vzN7etWBFWMmYMnHACXHEFmfnzaR+3m45VE3Prm1+TMuf3bd6uXQoKEWlAw+k/KQ6DKVPgc597a42k1gfD0kDbuhWuu26ABV9/PXQ454PhoYfClUpNTXDiiXDVVaEp6bTTYN99C58JyHywtmXO79t8jWLs2Prpn1JQiEjFhlsDyIfBDTfEc0VXab9J2UDbti1copoPhu7uUJjmZmhrg89/PgTDnDkwaVJNyjLYvOJp992nPgoRGQGqqQHEcUVXuX6T9nbouHsH2Ukrydz1c/hsJ6xaFXrOx46Fk0+Ga68NwTB7Nuy1V83K0tMTWqu+9S1YtKh8OeGt07797UJ4QH2EhYJCRBITR59E/2Ymp+PfHiNz53fJdHaSWb06DKw3bhyccgr8/d+HYDj1VJg4sfqND1CW/H0hfX1w5ZXhYqhMpvzT8gaaVm83XCooRCRRxTWSqofv2LKFrK+jxebQyxha9vSSvf0yGL86rPArXwnBcMopMH58zT5DOdls4XJfCAGQb14rV5sqnVaPN1wqKCRVo2lMI+lvWDfC/elPYUTV/JAYjz5KBmgfl6Xj0PPJvncMmQu/BiedFGoRCctkQnPTlVeGA/24cYVAKFebGmhavd1wqaCQ1IymMY3krSo6c960qXAPQ2cnPPFEmL733qHD+eMfh2yWzIknkmlpecs2yp2IxHmCsmhRaG4aaP0D9e+UTqvHGy4VFJKaeqxij0Zp1eoGbIrZsKF/MDz9dFh4n33CJaoXXxwWnDUrXKkUodyJSNT0Wu2Hai/5rbcbLhUUkpqROKZRo0l79Nb22zfRcccmsjvuJnP+LfDcc2HmfvvB3LnwqU+FPobjjx80GEqVOxEp16ms2m15CgpJTT1WsUebRGt17vD884V7GDo6yPzhD2QAJk8OgfCZz4Tfxx1X0fOeo2oB5U5EBpqu2m20VILCzK4GLgMcWAtc7O470yiLpKveqtgjzWDNKbHW6tzhmWf6BQMbNoR5U6eGQLjmmvD73e8OlwtVKD943ve+F26kHqgWUO5EpNx01W7LM3dPdoNmBwEPAEe7+w4zuxP4tbvfWu49bW1t3t3dnVQRRUaEqGal4gCBGtXq3OHJJ/sHw6ZNYd4BBxQe0DN/fhiCe5iP9cx/rp07wyYhVD4WLy4zTMcQ1jvSardmttLd26pdT1pNT83ABDPbBUwE/phSOSRFI/E/Zj0p15xSfPdwUxPcfPMwD7Du8NhjhWDo7AyXrwJMn94/GI48sqrnPRd/V/KfKx8SZrWpBah2W17iQeHuG83s68B6YAdwj7vfU7qcmS0CFgHMmDEj2UJK7HRpbPzKNSuV3j18xRWFu4cj9fXBunWFUFi6FLZsCfMOPhje//5CMBx+eMXBMNgJw0AjweY/V1MTXHJJfY2LNBIlHhRmNhk4G5gJvAr82MzOd/fbi5dz9yXAEghNT0mXU+KlzsO3qnUNq1xbfDYbDrDFT5YbcP/v2QNr1vQPhldeCfMOPRQ+9KFCrWHmzGHVGCo5YRhoJNjBLoJQbbW20mh6eh/wvLtvATCznwKzgdsj3yUjii6N7W/Jkv5389aqhlXuBq+bbw41ib6+oruHd++G1asLwXD//fDqq+FNhx0GZ59dqDG0tlZfOCo7YRjouxLVTKTaau2lERTrgVPNbCKh6WkBoJ7qUUaXxhYsWQKf/nThDL+nJ94aVldXOCv/1r/uZuvaTWStk8w/3hGG3962LSx0xBHwsY8VguGQQ2IpSyUnDEP9riRZWx0tNZc0+ihWmNlPgFXAbuD35JqYZHSp987DJA4CXV2FM/u8pqaYali7dtH1vSdYcOVR9O4aQwu9tPPXZFgORx0F551XCIa3v73i1VaznyoNgaF8V5KqrY6mmkvZoDCzXwN/4+4v1Hqj7v5l4Mu1Xq9IrSR1EOjo6B8SY8aEZqGabKunBx5+uHCp6rJldLzxWXpZzB6a6LVxdJzzHTI3HQAHHjisTdRiP9X6hCGp2upo6meLqlF8D7jHzL4P/LO770qoTCKpS+ogkM2GPoKBHnQzZDt3hmc854OhqytMg3Cn86WXkj3wA7QsbqJ3F7S0NJH97HEwvIwA6vdgOZTwGW6NaDT1s5UNCnf/sZndDXwJ6DazHwB9RfO/kUD5RFKR1EGgqrPfN96A5csLwbBiRUgcszA20uWXh2akuXPDw6oJz3puP712Z9uNfrCspkY0mvrZBuuj6AW2A+OASRQFhchIltRBYEhns9u3w7JlhWB46CHYtStURWbNCpdNzZ8fRlmdPLnsamrZ1JPEfoqzr6jaGlG997PVSlQfxULgG8AvgVnu/kZipRKpA3EfBAY9m33tNXjwwUIwdHeHS1ibmuDEE+Hqq0MwzJkD++4bX0EHEed+iruvqNFrREmJqlFcD/wPd380qcKI1EojXLb4lrPZ3+wk80p74T6GlSvDzObm8MS2L3whBMPs2TBpUtrFT0TcfSCjqfmoGlF9FHOTLIhIrTTKZYvZWdtoadqL3j5o6dtFdvEC8GUwdmx4xvO11xaOXnvtlXZxU5HEGf9oaT6qRsM/j6IRzhwlWfV6JQ5bt4ZhMHI1hswjj9Dup9DR9D6yx24l85H3QfYf4dRTYcKEtEtbF3TGXx8aOiga5cxRklU37c6bN/cLBtauDdMnTAhf1K98hUw2S+bkk2H8+JQKWf90xp++hg6Kuj1zlFSldhb60kv9h9x+7LEwfeLE0OF8zjmhQCedFBJMpEE0dFDUzZmjDFncTYaJnIVu3Ng/GJ58Mkzfe+9wieoFF4QPeOKJod8hR82l0mgaOijUftk4Sp+o1pBNhi++WLhUtbMzPOYTYJ99wk1tl14arkqaNStcqTQANZdKI2rooAC1XzaC0oPjRRfF32RYk7P2F17oHwzPPx+m77cfzJsXhnydPz/cBd3UVNEq1Vwqjajhg0LqX+nBEeJtMhzWWbs7PPdc/+c9r18f5u2/fwiEq64Kv489tuJgKKXmUmlECgqpWK0GT7vwwvCT6rAM7vD00/2DYePGMG/atBAI+RvcjjkmDJNRA2oulUakoJCKxDF4WrUHyXLBNeBZuzs88UT/zudNm8Ib3va2EAj5x3q+613DeqznYOXKU3OpNBoFhVQkrcHTyh10o4Irk4H2e/vo+PFmsk0PkLnpzhAMmzeHBd7+9rDCfDC8851VBUNpedVZLSONgkIqkkbbetRB9y3BdV8fmYlrC3c9d3aS2bo1LHzIIfCBDxSC4R3vqFkwlFJntYxECgqpSBpt61EH3ezcPbQ0WxgnyXeRvfEjcP09YWZrK5x5ZiEYWltjC4ZS6qyWkUhBIRUbrPmoVjeS5dczZUrxQdfJHvA4fP3XocZw//2097yLDrJk3/4MmQ8eDPO/H4Lh0EOHv/EqqbNaRiJz97TLMKi2tjbv7u5OuxgSoVZt84X1OC3NfXzzjHvY+uifyG64ncwb7WGhd74zBEL+5+CDa/thYqC7sSUNZrbS3duqXU8qNQoz2w/4LvBuwIFL3L0rjbJIbVTdNt/bC93ddHy1h94d89hDE717+tj6s6Vc965fwIXzYf5lIRimT4/pU8RDHdzS6NJqevoX4Dfu/jEzawEmplQOqZEht8339IRHeebvel62DHbsIMuptNjv6KWFlrFG9qdfgA/fEP8HiJE6uKXRJR4UZrYvMA/4BIC79xKezT2qxdE0kWRzx6Bt8zt3wvLlhZvbli8P08zguOPgk5+E+fPJzJtH+9MTitazf+RnquQzpt3sow5uaXjunugPcDzwEHAr8HtCE9ReAyy3COgGumfMmOEj2bJl7hMmuDc1hd/LltXnOodk+3b33/7W/Utfcp87172lxR3czdxPOMH96qvdf/5z961bK15l6Wf6znfC7zFj3MeODX8P9p7E90NROf7pn4a//WrfL6MT0O01OG6n0fTUDMwCPuPuK8zsX4BrgS8VL+TuS4AlEDqzEy9lguJomohjnZFn5q+/HpqP8jWGhx+GXbvC0BezZsFnPxv6F047LQyqNwyln+muu0ILVl9f+LniijAMU3HZ6qXZp5q7sdXHIWlLIyg2ABvcfUXu758QgmLUiqNpotbr7OqC008vrO++X20ns2tpIRhWroTdu8NgeW1tcPXVYaNz5oRhuGug9DN99KNw330hJCD8Lg2CSvZD2k1Tg6mXsJPRK/GgcPeXzOxFMzvS3Z8EFgCPJV2OehLHtfe1Xudt/6eHnp4WwOjpcW57/w/I8OnwQJ6TTgoD6GWzMHt2eHDPMFQyRtJAn+mKK0JIjBv31iAYbD80wtm6+jgkbWld9fQZ4Ie5K56eAy5OqRx1I46B4qpa5yuvwP33FwbQW3UZcHlh/qxZ8M+/DRuYWP1Fa5UesEs/06JFoblpuIPwNcLZum7ik7SlEhTuvhqo+iYQqaGXX4alSwvBsGZNGHF13DjIZLjwkrHc8oM+du0ew9ixxoU3nww1PGBVc8CuJhAb5WxdI85KmjSERx1IpY188+b+Q26vWxemT5gQmo+++tXQ+XzyyTB+PBmg47L4ypnWAbuSpimdyctopyE8UpZYG/mmTf2D4fHHw/S99godzvnhME46KRQkBfV2UG6E/guRKA09hEcjq/XBLLY28g0b+gfDU0+F6ZMmhUtUL7ooBMOJJ4YO6TpQb80rtfy3qbcQFBkKBcUQxHGGWbMml/XrC8NhdHbCs8+G6fvsA/PmvXnnMyecAM36Z69Erf5tVDORRqcjxhDEcfY/rCta3OGFFwr3MHR2hr8BJk+GuXPDNaPz58N73hPubRhEEme8jXZWXaurjRrhyiqRKAqKIYirw3XQJhf3UEMoDoYXXwzzpkwJNYarrw7BcOyx4W7oIUjijHeo2xhOqMQRRLVoDmuUK6tEylFQDEFi17O7hz6F4mD44x/DvGnTQiD83d+F30cfPeRgKJXEGe9QtjGc4Krn5h3dByGNTkExRLF0uLqHq5CKO59feinMO/BAuo65jI6TziR7ztvInHtozR/rmcQZ71C2MZzgqvfmnXrrqBcZCgVFGvr64NFH+wfDli1h3kEHwXvf++bznrtePoIF77NwgL0H2lvjuYN7OGe8Q2nqGco2hhNcat4RiU/DBUWjdYgCIRjWrCmEwtKlsHVrmDdjBixcGJqRslk47LB+NYaOu5I5U4464x1onw+nqafSs+rhBNdA72nI74pIHWqooBhu23XiB4s9e2D16v7B8OqrYd7MmXDWWYVgaG2NXFXaZ8rl9nncTT3Daaopfk8991mINJqGCoqhHpziOli8JXx274ZVqwrBcP/9sG1bWPjww8N42Pk7n2fMGNK2atURWmlgli5Xbp+nHWCDqfc+C5FG0lBBMdSDU1wP71mwwOntgZam3bTP+iKZR78bHtwDcOSRcO65hWA46KDqNkj1HaGVBuZAy5Xb5/V+JU+9B5lII2mooBjqwalmB4ve3vDEto4OOm6dTu+OC9lDM7190PHcDDIXXBBCYd48mD59mBuJT6WBOdBy111Xfp/X85U89R5kIo2koYIChnZwGvbBYudOeOihwj0MXV2wYwcA2cM+Tkvz+fT29dHS0kz2F1fXdLjtOFQamFG1h0Y80DZquQeijnlJk0aPhRACy5cXgmH58vAwZjM47rg3L1Vl7lyYOrUh/9MOt49C0qeOeRkujR5bje3bC0fEzs5Qe+jtDXc4H398YZykuXPD2Eklyp2p1vNBdiiXptZb2Uc7dcxL2kZHULz+Ojz4YCEYHn44XKnU1BQe6XnVVSEYTjsN9t13WJvQWZ/ERR3zkraRGRTbtsEDDxTGSlq5MpyONTdDWxtcc0343zZnDl3rJoVawP6QGV5GADrrk/ioY17SNjKC4tVXw70L+fsYVq0Kd0OPHRse5ZkfQG/2bNh77zffVstagM76JE5qEpQ0pRYUZtYEdAMb3f3MIb35lVfC3c75YFi9Ogys19ICp54K118fgiGTgYkT3/L2fF/C+vW1qwXorE9ERqo0axRXAY8D+wy65O7dcNddhWBYsyZMHz8+HJG//OUQDKecAhMmRK6quBbR3Fx4pk8tagE66xORkSiVoDCzg4EPA/8b+NtB3/DII/Cxj4UQmDMHFi8OwXDyyTBu3JC2XdyXAOEJoTNmNGYtoJ6vshKRkSOtGsU3gS8Ck8otYGaLgEUAR+23H/zXf4WO6JaWqjZc2pdw4YWNeZDVVVYikpTqHo02DGZ2JrDZ3VdGLefuS9y9zd3b9nrHO0JHdJUhAYW+hMWLow+uXV1www3hdz0a6CorEZE4pFGjmAN8xMzOAMYD+5jZ7e5+/mBvrFVTy2B9CY1wtq6rrEQkKYkHhbtfB1wHYGZZ4POVhkRSB+9GuCdCV1mJSFIa5j6KJA/ejXK2rqusRCQJqQaFu3cAHZUsm+TBW2frIiIFDVOjSPrgrbN1EZGgYYICdPAWEUlD4pfHiohIY1FQiIhIJAWFiIhEUlCIiEgkBYWIiERSUIiISCQFxQhT74MZikjjaaj7KCRaIwxmKCKNRzWKEURDj4tIHBQUI0h+PKympvoezFBEGouankYQDWYoInFQUIwwGg9LRGpNTU8iIhJJQSEiIpEUFCIiEklBISIikRQUIiISSUEhIiKREg8KMzvEzO4zs8fM7FEzuyrpMoiISOXSuI9iN3CNu68ys0nASjO7190fS6EsIiIyiMRrFO6+yd1X5V6/BjwOHJR0OUREpDKp9lGYWStwArBigHmLzKzbzLq3bNmSeNlERCRILSjMbG/gLuBz7r6tdL67L3H3NndvmzZtWvIFFBERIKWgMLOxhJD4obv/NI0yiIhIZdK46smA/wAed/dvJL19EREZmjRqFHOAC4D3mtnq3M8ZKZRDREQqkPjlse7+AGBJb1dERIZHd2aLiEgkBYWIiERSUIiISCQFhYiIRFJQiIhIJAWFiIhEUlCIiEgkBYWIiERSUIiISCQFhYiIRFJQiIhIJAWFiIhEUlCIiEgkBYWIiERSUIiISCQFhYiIRFJQiIhIJAWFiIhEUlCIiEgkBYWIiERKJSjMbKGZPWlmz5jZtWmUQUREKpN4UJhZE/At4EPA0cB5ZnZ00uUQEZHKpFGjOBl4xt2fc/de4D+Bs1Moh4iIVKA5hW0eBLxY9PcG4JTShcxsEbAo92ePma1LoGzVmgq8nHYhKqBy1k4jlBFUzlprlHIeWYuVpBEUFXH3JcASADPrdve2lIs0KJWzthqhnI1QRlA5a62RylmL9aTR9LQROKTo74Nz00REpA6lERQPA0eY2UwzawHOBX6ZQjlERKQCiTc9uftuM7sS+H9AE3CLuz86yNuWxF+ymlA5a6sRytkIZQSVs9ZGVTnN3WuxHhERGaF0Z7aIiERSUIiISKTUg2Kw4TzMbJyZ/Sg3f4WZtRbNuy43/Ukz+2CKZfxbM3vMzNaYWbuZHVo0b4+Zrc79xNppX0E5P2FmW4rKc1nRvIvM7Oncz0Upl/OmojI+ZWavFs1LZH+a2S1mtrnc/TsW/GvuM6wxs1lF85Lcl4OV8+O58q01s2Vm9p6ieS/kpq+u1WWUVZQza2Z/Kfq3/YeieYkN+VNBOb9QVMZ1ue/j/rl5iexPMzvEzO7LHXMeNbOrBlimtt9Pd0/th9CZ/SxwGNACPAIcXbLM3wD/nnt9LvCj3Oujc8uPA2bm1tOUUhlPBybmXn86X8bc36/X0b78BHDzAO/dH3gu93ty7vXktMpZsvxnCBc8JL0/5wGzgHVl5p8B3A0YcCqwIul9WWE5Z+e3Txg2Z0XRvBeAqXWyP7PAr6r9vsRdzpJlzwJ+l/T+BKYDs3KvJwFPDfB/vabfz7RrFJUM53E28P3c658AC8zMctP/09173P154Jnc+hIvo7vf5+5v5P5cTrg3JGnVDI3yQeBed3/F3f8M3AssrJNyngfcEVNZynL3pcArEYucDdzmwXJgPzObTrL7ctByuvuyXDkgve9mJfuznESH/BliOdP6bm5y91W5168BjxNGvChW0+9n2kEx0HAepR/4zWXcfTfwF2BKhe9NqozFLiUked54M+s2s+Vm9t9iKF9epeX8aK4q+hMzy9/4mNS+HNK2ck14M4HfFU1Oan8OptznSHJfDlXpd9OBe8xspYUhc9KWMbNHzOxuMzsmN60u96eZTSQcYO8qmpz4/rTQFH8CsKJkVk2/n3U7hEcjMrPzgTZgftHkQ919o5kdBvzOzNa6+7PplJD/C9zh7j1m9ilCTe29KZWlEucCP3H3PUXT6ml/NgwzO50QFKcVTT4tty8PAO41sydyZ9RpWEX4t33dzM4Afg4ckVJZKnEW8KC7F9c+Et2fZrY3Iag+5+7b4toOpF+jqGQ4jzeXMbNmYF9ga4XvTaqMmNn7gOuBj7h7T366u2/M/X4O6CCkfxwGLae7by0q23eBEyt9b5LlLHIuJVX7BPfnYMp9jrobosbMjiP8e5/t7lvz04v25WbgZ8TTdFsRd9/m7q/nXv8aGGtmU6nD/ZkT9d2MfX+a2VhCSPzQ3X86wCK1/X7G3fEySKdMM6EzZSaFjqpjSpa5gv6d2XfmXh9D/87s54inM7uSMp5A6HA7omT6ZGBc7vVU4Gli6oirsJzTi17/d2C5Fzq4ns+Vd3Lu9f5plTO33FGEzkFLY3/mttFK+c7XD9O/s/ChpPdlheWcQei/m10yfS9gUtHrZcDCFMt5YP7fmnCAXZ/btxV9X5IqZ27+voR+jL3S2J+5/XIb8M2IZWr6/YxtZw/hQ59B6LV/Frg+N+1/Ec7MAcYDP8592R8CDit67/W59z0JfCjFMv4W+BOwOvfzy9z02cDa3Jd7LXBpyvvyBuDRXHnuA44qeu8luX38DHBxmuXM/f0V4MaS9yW2Pwlni5uAXYR23EuBy4HLc/ON8ACuZ3NlaUtpXw5Wzu8Cfy76bnbnph+W24+P5L4T16dcziuLvpvLKQq2gb4vaZUzt8wnCBfSFL8vsf1JaD50YE3Rv+sZcX4/NYSHiIhESruPQkRE6pyCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKEQi5IZ0fr5oKOnJub9byyz/GzN71cx+lWhBRWKkoBCJ4O4vAt8GbsxNuhFY4u4vlHnL14ALEiiaSGIUFCKDuwk41cw+R7gr9uvlFnT3duC1hMolkgiNHisyCHffZWZfAH4DfMDdd6VdJpEkqUYhUpkPEcYAenfaBRFJmoJCZBBmdjzwfsIonFfnnhQmMmooKEQi5B67+23Cw2HWEzqry/ZRiIxECgqRaJ8E1rv7vbm//w14l5nNH2hhM7ufMCz+AjPbYGYfTKicIrHRMOMiIhJJNQoREYmky2NFhsjMjgV+UDK5x91PSaM8InFT05OIiERS05OIiERSUIiISCQFhYiIRFJQiIhIpP8PItsOwIL9crwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_new,y_predict,\"r-\")\n",
    "plt.plot(X,y,\"b.\")\n",
    "plt.xlabel(\"X_1\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.axis([0,2,0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LinearRegression class is based on the np.linalg.lstsq() function which you could call directly. \n",
    "\n",
    "This function computes $\\theta = X^+ y $, where $X^+$ is the **pseudoinverse** of X. You can use np.linalg.pinv() to compute the pseudo inverse directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.00499775],\n",
       "       [2.8540897 ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b,y,rcond = 1e-6)\n",
    "theta_best_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.00499775],\n",
       "       [2.8540897 ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.pinv(X_b).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pseudoinverse itself is computed using a standard matrix factorization technique called **Singular Value Decomposition (SVD)** that can decompose the training set matrix X into the matrix multiplication of three matrices $ U, \\sum, V^T$. The pseudoinverse is computed as $X^+ = V\\sum^{+}U^T$.\n",
    "\n",
    "The normal equation may not work if the matrix $X^TX$ is not invertible (i.e singular). Hence SVD method is normally used to calculate theta_best.\n",
    "\n",
    "##### Computational Complexity\n",
    "The normal equation for finding theta best is:  \n",
    "\n",
    "\n",
    "$\\theta = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "This equation computes the inverse of $X^TX$ which is an $(n+1)*(n+1)$ matrix (where n is the number of features). The *Computational complexity* of inverting such a matrix is typically about $O(n^{2.4})$ to $O(n^3)$ depending upon the implementation.  \n",
    "\n",
    "The SVD approach used by Scikit-Learn's LinearRegression class is about $O(n^2)$. \n",
    "\n",
    "\n",
    "## Gradient Descent\n",
    "### 1) Batch Gradient Descent\n",
    "Now we will look at very different ways to train a Linear Regression model, better suited for cases where there are a large number of features, or too many training instances to fit in memory. \n",
    "\n",
    "The idea of Gradient Descent is to tweak parameters ($\\theta$) iteratively in order to minimize a cost function.  \n",
    "\n",
    "You can calculate the gradient descent using the following formula on the go.\n",
    "$MSE(\\theta) = \\frac{2}{m} X^T(X\\theta - y)$\n",
    "\n",
    "and use this gradient to tweak the parameters ($\\theta$)  \n",
    "\n",
    "$ \\theta^{(next step)} = \\theta - \\eta * MSE(\\theta) $\n",
    "\n",
    "where $\\eta$ (eta) is the learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00499775]\n",
      " [2.8540897 ]]\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1 #learning rate\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2,1) #random initialization of theta\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T @ (X_b @ theta - y)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Stochastic Gradient Descent\n",
    "The main problem with Batch Gradient Descent is the fact that it uses the whole training set to compute the gradients at every step, which makes it very slow when the training set is large. \n",
    "\n",
    "However, **Stochastic gradient descent** just picks a random instance in the training set at every step and computes the gradients based only on that single instance. This makes it possible to train on huge datasets, since only one instance needs to be in memory at each iteration.\n",
    "\n",
    "Because of stochastic nature, the algorithm is much less regular than Batch Gradient Descent: instead of gently decreasing until it reaches the minimum, the cost function will bounce up and down, decreasing only on average. Overtime it will end up very close to the minimum, but once it gets there it will continue to bounce around, never settling down. So once the algorithm stops, the final parameter value are good, but not optimal. \n",
    "\n",
    "- When the cost function is very irregular, this can actually help the algorithm jump out of local minima, so SGD has a better chance of finding the global minimum than BGD.\n",
    "\n",
    "To solve SGD problem, we can gradually reduce the learning rate. The step starts out with large learning rate, and then gets smaller and smaller, allowing the algorithm to settle at global minima. The function that determines the learning rate at each iteration is called the **learning schedule**. \n",
    "\n",
    "The implementation of SGD is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "t0,t1 = 5,50 # learning schedule hyperparameters. \n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2,1) # random initialization\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T @ (xi @ theta - yi)\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.01093715],\n",
       "       [2.85442046]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
